{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:29:55.298747Z",
     "start_time": "2020-08-20T03:29:55.250084Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:33:15.641485Z",
     "start_time": "2020-08-20T03:33:15.587153Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T03:30:10.451461Z",
     "start_time": "2020-08-20T03:30:10.396204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/img_wang\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:13:34.824603Z",
     "start_time": "2020-08-20T04:13:34.767090Z"
    }
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(x1, x2, y, m=1., p=2, reduction='mean'):\n",
    "    \"\"\"\n",
    "    # TODO: find out what a reasonable value for m (margin) is.\n",
    "    \n",
    "    Note: \n",
    "    \n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1: torch.Tensor\n",
    "        Shape (bs, n_features).\n",
    "    x2: torch.Tensor\n",
    "        Shape (bs, n_features).\n",
    "    y: torch.Tensor\n",
    "        Labels. Unlike the paper, we use the convention that a label of 1 \n",
    "        means images are similar. This is consistent with all our existing\n",
    "        datasets and just feels more intuitive.\n",
    "    m: float\n",
    "        Margin that prevents dissimilar pairs from affecting the loss unless\n",
    "        they are sufficiently far apart. I believe the reasonable range of\n",
    "        values depends on the size of the feature dimension.\n",
    "    p: int\n",
    "        The p that determines the p-norm used to calculate the initial \n",
    "        distance measure between x1 and x2. The default of 2 therefore uses\n",
    "        euclidean distance.\n",
    "    reduction: str\n",
    "        One of ('sum', 'mean', 'none'). Standard pytorch loss reduction. Keep\n",
    "        in mind 'none' will probably not allow backpropagation since it\n",
    "        returns a rank 2 tensor.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor: Scalar measuring the contrastive loss. If no reduction is\n",
    "    applied, this will instead be a tensor of shape (bs,).\n",
    "    \"\"\"\n",
    "    reduction = identity if reduction == 'none' else getattr(torch, reduction)\n",
    "    dw = F.pairwise_distance(x1, x2, p, keepdim=True) \n",
    "    # Loss_similar + Loss_different\n",
    "    res = y*dw.pow(p).div(2) + (1-y)*torch.clamp_min(m-dw, 0).pow(p).div(2)\n",
    "    return reduction(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:14:54.618543Z",
     "start_time": "2020-08-20T04:14:54.545233Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, m=1., p=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.loss = partial(contrastive_loss, m=m, p=p, reduction=reduction)\n",
    "        \n",
    "    def forward(self, x1, x2, y_true):\n",
    "        return self.loss(x1, x2, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:15:56.157235Z",
     "start_time": "2020-08-20T04:15:56.103606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.8909,  20.2486,  39.7307,  60.3099,  81.7360],\n",
      "        [-50.2483, -49.1922, -50.7428, -50.1480, -48.9504]])\n",
      "tensor([[ 0.9450, 19.3297, 39.5396, 59.4475, 79.7256],\n",
      "        [24.4308, 24.5980, 26.0160, 25.4062, 22.6329]])\n"
     ]
    }
   ],
   "source": [
    "bs = 2\n",
    "x1 = torch.randn(bs, 5)\n",
    "x2 = torch.randn(bs, 5)\n",
    "x1[0] += torch.arange(0, 100, 20)\n",
    "x1[1] -= 50\n",
    "x2[0] += torch.arange(0, 100, 20)\n",
    "x2[1] += 25\n",
    "\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:16:00.062420Z",
     "start_time": "2020-08-20T04:15:59.987436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1, 0]).unsqueeze(-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:16:00.890352Z",
     "start_time": "2020-08-20T04:16:00.852120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6403)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ContrastiveLoss()\n",
    "loss(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:16:01.802935Z",
     "start_time": "2020-08-20T04:16:01.704481Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6403)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss(x1, x2, y, m=1, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:18:52.563843Z",
     "start_time": "2020-08-20T04:18:52.483836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1388.6364)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like I'll need to make some adjustments if I want this to work well\n",
    "# with non-binary targets.\n",
    "y_reg = torch.tensor([.8, .2]).unsqueeze(-1)\n",
    "loss(x1, x2, y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:19:16.315876Z",
     "start_time": "2020-08-20T04:19:16.201635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9999, -0.9994])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:20:27.200103Z",
     "start_time": "2020-08-20T04:20:27.073104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.5615, 166.5728])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pairwise_distance(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:25:20.642235Z",
     "start_time": "2020-08-20T04:25:20.524714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.2360e-05, 1.9994e+00])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not exactly sure what target is supposed to be.\n",
    "F.cosine_embedding_loss(x1, x2, torch.tensor(1), reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- confirm good value of margin\n",
    "- try alternate formula I found using softmax and cosine distance\n",
    "- try to make code work with non-binary targets (proba instead of 0/1)\n",
    "- think about how this might work for my problem where I have 3 pairs per row (if a row contains x_new, x1, x2, x3, we have x_new:x1, x_new:x2, and x_new:x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
