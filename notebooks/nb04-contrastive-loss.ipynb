{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:38:47.168163Z",
     "start_time": "2020-08-22T03:38:47.095892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:38:47.325758Z",
     "start_time": "2020-08-22T03:38:47.254054Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from htools import *\n",
    "from img_wang.models import ClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:38:48.680166Z",
     "start_time": "2020-08-22T03:38:48.631750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/img_wang\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:13:34.824603Z",
     "start_time": "2020-08-20T04:13:34.767090Z"
    }
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(x1, x2, y, m=1., p=2, reduction='mean'):\n",
    "    \"\"\"\n",
    "    # TODO: find out what a reasonable value for m (margin) is.\n",
    "    \n",
    "    Note: \n",
    "    \n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1: torch.Tensor\n",
    "        Shape (bs, n_features).\n",
    "    x2: torch.Tensor\n",
    "        Shape (bs, n_features).\n",
    "    y: torch.Tensor\n",
    "        Labels. Unlike the paper, we use the convention that a label of 1 \n",
    "        means images are similar. This is consistent with all our existing\n",
    "        datasets and just feels more intuitive.\n",
    "    m: float\n",
    "        Margin that prevents dissimilar pairs from affecting the loss unless\n",
    "        they are sufficiently far apart. I believe the reasonable range of\n",
    "        values depends on the size of the feature dimension.\n",
    "    p: int\n",
    "        The p that determines the p-norm used to calculate the initial \n",
    "        distance measure between x1 and x2. The default of 2 therefore uses\n",
    "        euclidean distance.\n",
    "    reduction: str\n",
    "        One of ('sum', 'mean', 'none'). Standard pytorch loss reduction. Keep\n",
    "        in mind 'none' will probably not allow backpropagation since it\n",
    "        returns a rank 2 tensor.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor: Scalar measuring the contrastive loss. If no reduction is\n",
    "    applied, this will instead be a tensor of shape (bs,).\n",
    "    \"\"\"\n",
    "    reduction = identity if reduction == 'none' else getattr(torch, reduction)\n",
    "    dw = F.pairwise_distance(x1, x2, p, keepdim=True) \n",
    "    # Loss_similar + Loss_different\n",
    "    res = y*dw.pow(p).div(2) + (1-y)*torch.clamp_min(m-dw, 0).pow(p).div(2)\n",
    "    return reduction(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:38:18.463520Z",
     "start_time": "2020-08-22T04:38:18.389905Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss1d(nn.Module):\n",
    "    \n",
    "    def __init__(self, m=1., p=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.loss = partial(contrastive_loss, m=m, p=p, reduction=reduction)\n",
    "        \n",
    "    def forward(self, x1, x2, y_true):\n",
    "        return self.loss(x1, x2, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:27:02.137759Z",
     "start_time": "2020-08-22T04:27:02.051494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.4772,  20.1164,  41.4341,  59.0182,  78.2542],\n",
      "        [-49.2596, -50.2114, -50.6976, -49.3883, -49.9065]])\n",
      "tensor([[-2.3021e-02,  1.9816e+01,  3.8695e+01,  5.8490e+01,  7.9823e+01],\n",
      "        [ 2.3965e+01,  2.4299e+01,  2.4448e+01,  2.5086e+01,  2.3895e+01]])\n"
     ]
    }
   ],
   "source": [
    "bs = 2\n",
    "x1 = torch.randn(bs, 5)\n",
    "x2 = torch.randn(bs, 5)\n",
    "x1[0] += torch.arange(0, 100, 20)\n",
    "x1[1] -= 50\n",
    "x2[0] += torch.arange(0, 100, 20)\n",
    "x2[1] += 25\n",
    "\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:27:21.254647Z",
     "start_time": "2020-08-22T04:27:21.162713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1, 0]).unsqueeze(-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:38:22.951790Z",
     "start_time": "2020-08-22T04:38:22.883116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1123)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ContrastiveLoss1d(reduction='mean')\n",
    "loss(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:38:32.649228Z",
     "start_time": "2020-08-22T04:38:32.602110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2247],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ContrastiveLoss1d(reduction='none')\n",
    "loss(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:05:12.538024Z",
     "start_time": "2020-08-22T04:05:12.353179Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2806],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss(x1, x2, y, m=1, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:37:55.291647Z",
     "start_time": "2020-08-22T04:37:55.215211Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, m=1., p=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "        self.p = p\n",
    "        self.loss = partial(contrastive_loss, m=m, p=p, reduction='none')\n",
    "        \n",
    "        if reduction == 'none':\n",
    "            self.reduction = identity\n",
    "        elif reduction == 'row':\n",
    "            self.reduction = partial(torch.sum, dim=-1)\n",
    "        else:\n",
    "            self.reduction = getattr(torch, reduction)\n",
    "        \n",
    "    def forward(self, x1, x2, y_true):\n",
    "        # x1 has shape (bs, feats). x2 has shape (bs, n_item, n_feats).\n",
    "        # I.E. we're comparing 1 image to `n_item` variants.\n",
    "        # y_true has shape (bs, n_item).\n",
    "        # Basically multi-label classification with OHE labels.\n",
    "        # Output is scalar if reduction is 'mean' or 'sum', same shape as y\n",
    "        # if reduction is 'none', or shape (bs,) if reduction is 'row'.\n",
    "        bs, n, dim = x2.shape\n",
    "        res = self.loss(x1.repeat_interleave(n, dim=0), \n",
    "                        x2.view(-1, dim),\n",
    "                        y_true.view(-1, 1))\n",
    "        return self.reduction(res.view(bs, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:26.416493Z",
     "start_time": "2020-08-22T04:35:26.354850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[7.2080e-02, 1.9909e+01, 3.8723e+01, 5.8513e+01, 7.9828e+01],\n",
       "         [4.2575e+00, 2.8752e+01, 4.4914e+01, 6.1409e+01, 8.9757e+01],\n",
       "         [8.2325e+00, 2.3834e+01, 3.9332e+01, 5.8804e+01, 8.2293e+01]],\n",
       "\n",
       "        [[2.5705e+01, 3.2525e+01, 2.4480e+01, 3.1325e+01, 2.7094e+01],\n",
       "         [2.4503e+01, 2.9017e+01, 2.6627e+01, 2.6928e+01, 2.9855e+01],\n",
       "         [5.2564e+02, 5.2743e+02, 5.2514e+02, 5.3094e+02, 5.3027e+02]]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = torch.rand(2, 3, 5) * 10\n",
    "noise[0, 0] /= 100\n",
    "noise[-1, -1] += 500\n",
    "x3 = x2[:, None, ...] + noise\n",
    "print(x3.shape)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:26.911100Z",
     "start_time": "2020-08-22T04:35:26.862584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1],\n",
       "        [1, 1, 0]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2d = torch.tensor([[1, 0, 1],\n",
    "                    [1, 1, 0]])\n",
    "y2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:28.473371Z",
     "start_time": "2020-08-22T04:35:28.379215Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]), torch.Size([2, 3, 5]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x3.shape, y2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:29.712460Z",
     "start_time": "2020-08-22T04:35:29.622570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   70.6990, 30221.8262])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2d = ContrastiveLoss2d(reduction='row')\n",
    "res = loss2d(x1, x3, y2d)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:30.641602Z",
     "start_time": "2020-08-22T04:35:30.587134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2623e+00, 0.0000e+00, 6.4437e+01],\n",
       "        [1.5280e+04, 1.4942e+04, 0.0000e+00]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2d = ContrastiveLoss2d(reduction='none')\n",
    "res = loss2d(x1, x3, y2d)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:36.886399Z",
     "start_time": "2020-08-22T04:35:36.807352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5048.7544)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2d = ContrastiveLoss2d(reduction='mean')\n",
    "res = loss2d(x1, x3, y2d)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:35:38.136353Z",
     "start_time": "2020-08-22T04:35:38.085176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30292.5254)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2d = ContrastiveLoss2d(reduction='sum')\n",
    "res = loss2d(x1, x3, y2d)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:23:52.479475Z",
     "start_time": "2020-08-22T04:23:52.420841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1057e+00, 0.0000e+00, 1.2657e+02],\n",
       "        [1.6185e+04, 1.5624e+04, 0.0000e+00]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.view(x1.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:20:13.925782Z",
     "start_time": "2020-08-22T04:20:13.857615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.8909,  20.2486,  39.7307,  60.3099,  81.7360],\n",
       "        [-50.2483, -49.1922, -50.7428, -50.1480, -48.9504]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:10:02.327735Z",
     "start_time": "2020-08-22T04:10:02.249204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.9451,  19.4059,  39.5839,  59.4560,  79.7724],\n",
       "         [ 10.8960,  27.8966,  42.8544,  65.2645,  89.4107],\n",
       "         [  2.1223,  27.9709,  48.9245,  67.1623,  89.6087]],\n",
       "\n",
       "        [[ 32.8121,  28.1083,  27.9012,  32.6898,  31.3549],\n",
       "         [ 26.2665,  33.0588,  29.6756,  30.8534,  25.8869],\n",
       "         [525.0332, 527.2878, 530.2631, 529.9833, 531.0088]]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:10:36.610647Z",
     "start_time": "2020-08-22T04:10:36.539779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.9451,  19.4059,  39.5839,  59.4560,  79.7724],\n",
       "        [ 10.8960,  27.8966,  42.8544,  65.2645,  89.4107],\n",
       "        [  2.1223,  27.9709,  48.9245,  67.1623,  89.6087],\n",
       "        [ 32.8121,  28.1083,  27.9012,  32.6898,  31.3549],\n",
       "        [ 26.2665,  33.0588,  29.6756,  30.8534,  25.8869],\n",
       "        [525.0332, 527.2878, 530.2631, 529.9833, 531.0088]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.view(-1, x3.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:13:31.036918Z",
     "start_time": "2020-08-22T04:13:30.951310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.8909,  20.2486,  39.7307,  60.3099,  81.7360],\n",
       "        [-50.2483, -49.1922, -50.7428, -50.1480, -48.9504]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:18:24.720515Z",
     "start_time": "2020-08-22T04:18:24.571634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.repeat_interleave(x3.shape[1], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:21:55.393501Z",
     "start_time": "2020-08-22T04:21:55.312505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2d.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:18:29.200329Z",
     "start_time": "2020-08-22T04:18:29.092133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.view(-1, x3.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:06:58.966027Z",
     "start_time": "2020-08-22T04:06:58.908486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T04:06:36.181753Z",
     "start_time": "2020-08-22T04:06:36.080520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pairwise_distance(x1[:, None, :], x3, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:18:52.563843Z",
     "start_time": "2020-08-20T04:18:52.483836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1388.6364)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like I'll need to make some adjustments if I want this to work well\n",
    "# with non-binary targets.\n",
    "y_reg = torch.tensor([.8, .2]).unsqueeze(-1)\n",
    "loss(x1, x2, y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:19:16.315876Z",
     "start_time": "2020-08-20T04:19:16.201635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9999, -0.9994])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:20:27.200103Z",
     "start_time": "2020-08-20T04:20:27.073104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.5615, 166.5728])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pairwise_distance(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T04:25:20.642235Z",
     "start_time": "2020-08-20T04:25:20.524714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.2360e-05, 1.9994e+00])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not exactly sure what target is supposed to be.\n",
    "F.cosine_embedding_loss(x1, x2, torch.tensor(1), reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [] confirm good value of margin\n",
    "- [X] try alternate formula I found using softmax and cosine distance\n",
    "- [] try to make code work with non-binary targets (proba instead of 0/1)\n",
    "- [] think about how this might work for my problem where I have 3 pairs per row (if a row contains x_new, x1, x2, x3, we have x_new:x1, x_new:x2, and x_new:x3)\n",
    "- [] think how this will work with incendio (requires x to be passed in). Maybe just use another library? Or could I make this a layer, like my SimilarityHead below? Would probably need to separate the functionality between the layer and loss func, as I did in SimilarityHead: need to investigate what loss function would be appropriate in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineSimilarityHead\n",
    "\n",
    "For other contrastive loss variant, I think it's simplest to do the cosine similarity and temperature scaling in the classification head and then leave log softmax for the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T04:52:34.930399Z",
     "start_time": "2020-08-21T04:52:34.836806Z"
    }
   },
   "outputs": [],
   "source": [
    "from img_wang.models import SmoothLogSoftmax, SmoothSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T04:52:26.297373Z",
     "start_time": "2020-08-21T04:52:26.233736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(SmoothLogSoftmax()(x1)).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T04:54:11.211299Z",
     "start_time": "2020-08-21T04:54:11.108601Z"
    }
   },
   "outputs": [],
   "source": [
    "out = SmoothSoftmax()(x1)\n",
    "assert torch.isclose(out.sum(-1), \n",
    "                     torch.ones(x1.shape[0])).all()\n",
    "assert torch.isclose(torch.exp(SmoothLogSoftmax()(x1)), out).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:51:16.194960Z",
     "start_time": "2020-08-22T03:51:16.109130Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimilarityHead(ClassificationHead):\n",
    "    \n",
    "    def __init__(self, similarity=None, temperature='auto'):\n",
    "        \"\"\"This should be used with nn.NLLLoss since it ends with a \n",
    "        log_softmax operation.\n",
    "        \"\"\"\n",
    "        super().__init__(last_act='log_softmax', temperature=temperature)\n",
    "        self.similarity = similarity or nn.CosineSimilarity(dim=-1)\n",
    "        warnings.warn('Remember to use nn.NLLLoss when using SimilarityHead.')\n",
    "        \n",
    "    def _forward(self, x_new, x_stack):\n",
    "        return self.similarity(x_new[:, None, ...], x_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:41:15.702253Z",
     "start_time": "2020-08-22T03:41:15.643305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]), torch.Size([2, 3, 5]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:47:56.299369Z",
     "start_time": "2020-08-22T03:47:56.218915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11278.1543,   8144.6191])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.kl_div(x1, x3[:, 0, :], reduction='none').sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:48:42.061894Z",
     "start_time": "2020-08-22T03:48:41.953140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.8909,  20.2486,  39.7307,  60.3099,  81.7360],\n",
       "        [-50.2483, -49.1922, -50.7428, -50.1480, -48.9504]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:48:55.000874Z",
     "start_time": "2020-08-22T03:48:54.931452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3709e+00, -3.4910e+02, -1.4322e+03, -3.3900e+03, -6.3209e+03]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.kl_div(x1[:1], x1[:1], reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:38:55.973477Z",
     "start_time": "2020-08-22T03:38:55.919735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimilarityHead(\n",
       "  (last_act): SmoothLogSoftmax(\n",
       "    (act): LogSoftmax(dim=-1)\n",
       "  )\n",
       "  (similarity): CosineSimilarity()\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = SimilarityHead()\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:39:04.135183Z",
     "start_time": "2020-08-22T03:39:04.073560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.8909,  20.2486,  39.7307,  60.3099,  81.7360],\n",
       "        [-50.2483, -49.1922, -50.7428, -50.1480, -48.9504]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:39:16.749205Z",
     "start_time": "2020-08-22T03:39:16.681061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0976, -1.0997, -1.0985],\n",
       "        [-1.0985, -1.0974, -1.0999]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = head(x1, x3)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T03:39:20.762651Z",
     "start_time": "2020-08-22T03:39:20.702769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3337, 0.3330, 0.3334],\n",
       "        [0.3334, 0.3337, 0.3329]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
